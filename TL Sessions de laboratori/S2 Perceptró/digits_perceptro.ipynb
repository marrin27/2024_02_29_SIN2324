{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marrin27/2024_02_29_SIN2324/blob/main/TL%20Sessions%20de%20laboratori/S2%20Perceptr%C3%B3/digits_perceptro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSmOIronvd48"
      },
      "source": [
        "# Perceptró aplicat a digits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upMNTp_avd5C"
      },
      "source": [
        "**Lectura del corpus:** $\\;$ comprovem també que les matrius de dades i etiquetes tenes les files i columnes que toca"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ih9xkwqvd5H"
      },
      "source": [
        "**Partició del corpus:** $\\;$ Creem un split de digits amb un $20\\%$ de dades per a test i la resta per a entrenament (training), barallant prèviament les dades d'acord amb una llavor donada per a la generació de nombres aleatoris. Ací, com en tot codi que incloga aleatorietat (que requerisca generar nombres aleatoris), convé fixar la dita llavor per a poder reproduir experiments amb exactitud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hJqTdanhvd5D",
        "outputId": "89526855-ae77-4cf9-d07b-f74c44991ab9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1437, 64) (360, 64)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np; from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "digits = load_digits(); X = digits.data.astype(np.float16); X/=X.max() # esto ultimo normaliza los valores para estar entre 0 y 1\n",
        "y = digits.target.astype(np.uint).reshape(-1, 1); # convierte las etiquetas de clases en enteros sin signo, y reorganiza el array para que sea de 64x1\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=23)\n",
        "print(X_train.shape, X_test.shape)\n",
        "# print(X.shape, y.shape, \"\\n\", np.hstack([X, y])[:5, :]) imprime las 5 primeras filas, con los valores de sus atributos + su etiqueta de clase"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como funciona reshape con un array sencillo\n"
      ],
      "metadata": {
        "id": "VQAfATc6CQOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np; A=np.array([[1,2],[3,4]]).reshape(4,1); A"
      ],
      "metadata": {
        "id": "WYaL4bDsw83D",
        "outputId": "f13f9a1f-8187-4c40-bde6-bc988871381a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [2],\n",
              "       [3],\n",
              "       [4]])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZbBqBIivd5J"
      },
      "source": [
        "**Implementació de Perceptró:** $\\;$ torna pesos en notació homogènia, $\\mathbf{W}\\in\\mathbb{R}^{(1+D)\\times C};\\;$ també el nombre d'errors i iteracions executades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Fa7ZHVjuvd5J"
      },
      "outputs": [],
      "source": [
        "def perceptro(X, y, b=0.1, a=1.0, K=200):\n",
        "    N, D = X.shape; Y = np.unique(y); C = Y.size; W = np.zeros((1+D, C))\n",
        "    for k in range(1, K+1):\n",
        "        E = 0\n",
        "        for n in range(N):\n",
        "            xn = np.array([1, *X[n, :]])\n",
        "            cn = np.squeeze(np.where(Y==y[n]))\n",
        "            gn = W[:,cn].T @ xn; err = False\n",
        "            for c in np.arange(C):\n",
        "                if c != cn and W[:,c].T @ xn + b >= gn:\n",
        "                    W[:, c] = W[:, c] - a*xn; err = True\n",
        "            if err:\n",
        "                W[:, cn] = W[:, cn] + a*xn; E = E + 1\n",
        "        if E == 0:\n",
        "            break;\n",
        "    return W, E, k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2WHnrQ6vd5K"
      },
      "source": [
        "**Aprenentatge d'un classificador (lineal) amb Perceptró:** $\\;$ Perceptró minimitza el nombre d'errors d'entrenament (amb marge)\n",
        "$$\\mathbf{W}^*=\\operatorname*{argmin}_{\\mathbf{W}=(\\boldsymbol{w}_1,\\dotsc,\\boldsymbol{w}_C)}\\sum_n\\;\\mathbb{I}\\biggl(\\max_{c\\neq y_n}\\;\\boldsymbol{w}_c^t\\boldsymbol{x}_n+b \\;>\\; \\boldsymbol{w}_{y_n}^t\\boldsymbol{x}_n\\biggr)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "A7jEse1gvd5M",
        "outputId": "18c113fc-0dd7-4f7f-8635-66467709fd01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre d'iteracions executades:  111\n",
            "Nombre d'errors d'entrenament:  0\n",
            "Vectors de pesos de les classes (en columnes i amb notació homogènia):\n",
            " [[-1.490000e+02 -1.820000e+02 -1.480000e+02 -1.520000e+02 -1.330000e+02\n",
            "  -1.580000e+02 -1.500000e+02 -1.490000e+02 -1.580000e+02 -1.810000e+02]\n",
            " [ 0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n",
            "   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00]\n",
            " [-8.750000e-01 -1.750000e+00  1.250000e+00  4.687500e+00 -2.625000e+00\n",
            "   4.375000e-01 -1.937500e+00  2.062500e+00 -3.812500e+00 -1.050000e+01]\n",
            " [-5.643750e+01 -6.143750e+01 -5.650000e+01 -5.900000e+01 -5.650000e+01\n",
            "  -2.868750e+01 -6.187500e+01 -5.062500e+01 -4.843750e+01 -5.637500e+01]\n",
            " [-1.063750e+02 -9.337500e+01 -1.074375e+02 -1.080625e+02 -1.363125e+02\n",
            "  -1.145000e+02 -1.116875e+02 -1.003750e+02 -1.144375e+02 -8.893750e+01]\n",
            " [-1.108750e+02 -1.546250e+02 -1.094375e+02 -8.437500e+01 -1.203750e+02\n",
            "  -1.091875e+02 -1.175000e+02 -1.068750e+02 -1.116875e+02 -1.034375e+02]\n",
            " [-7.112500e+01 -3.537500e+01 -6.343750e+01 -6.175000e+01 -8.406250e+01\n",
            "  -4.437500e+01 -7.375000e+01 -5.875000e+01 -6.675000e+01 -6.493750e+01]\n",
            " [-2.250000e+01 -2.025000e+01 -1.956250e+01 -1.643750e+01 -2.006250e+01\n",
            "   9.375000e+00 -9.625000e+00 -3.625000e+00 -3.031250e+01 -4.875000e+00]\n",
            " [-1.812500e+00 -1.750000e+00 -5.625000e-01 -2.500000e+00  6.437500e+00\n",
            "  -3.937500e+00 -1.125000e+00  1.562500e+00 -3.937500e+00 -3.000000e+00]\n",
            " [ 0.000000e+00  0.000000e+00 -7.500000e-01 -3.750000e-01 -1.250000e-01\n",
            "   5.000000e-01  0.000000e+00  0.000000e+00  4.375000e-01 -6.250000e-02]\n",
            " [-2.087500e+01 -3.712500e+01 -3.375000e+00 -1.100000e+01 -1.556250e+01\n",
            "  -2.225000e+01 -2.862500e+01 -1.500000e+01 -1.506250e+01 -1.500000e+01]\n",
            " [-1.159375e+02 -1.397500e+02 -1.138750e+02 -9.975000e+01 -1.180000e+02\n",
            "  -1.036250e+02 -1.193750e+02 -1.012500e+02 -1.100000e+02 -1.071250e+02]\n",
            " [-1.144375e+02 -1.248750e+02 -1.320625e+02 -1.126250e+02 -1.311250e+02\n",
            "  -1.205625e+02 -1.172500e+02 -1.143125e+02 -1.142500e+02 -1.195625e+02]\n",
            " [-1.085625e+02 -9.975000e+01 -9.456250e+01 -9.737500e+01 -1.305625e+02\n",
            "  -1.103125e+02 -1.250000e+02 -8.537500e+01 -1.251250e+02 -1.172500e+02]\n",
            " [-9.187500e+01 -9.762500e+01 -9.231250e+01 -8.468750e+01 -1.063750e+02\n",
            "  -9.412500e+01 -9.300000e+01 -9.800000e+01 -8.756250e+01 -9.450000e+01]\n",
            " [-2.650000e+01 -3.887500e+01 -2.550000e+01 -1.156250e+01 -2.862500e+01\n",
            "  -2.006250e+01 -1.787500e+01 -2.537500e+01 -1.250000e+01 -2.106250e+01]\n",
            " [-1.125000e+00 -1.375000e+00 -3.750000e-01 -2.125000e+00  3.687500e+00\n",
            "  -1.187500e+00 -2.500000e-01  2.187500e+00 -5.625000e-01 -3.187500e+00]\n",
            " [ 0.000000e+00  0.000000e+00 -3.750000e-01 -1.875000e-01 -6.250000e-02\n",
            "   0.000000e+00  0.000000e+00  0.000000e+00  4.375000e-01  0.000000e+00]\n",
            " [-2.643750e+01 -1.681250e+01 -3.500000e+01 -2.656250e+01 -2.631250e+01\n",
            "  -3.131250e+01 -3.631250e+01 -4.887500e+01 -2.118750e+01 -2.893750e+01]\n",
            " [-1.088125e+02 -1.132500e+02 -1.112500e+02 -1.326875e+02 -1.059375e+02\n",
            "  -1.043125e+02 -1.000000e+02 -1.277500e+02 -1.055625e+02 -1.043125e+02]\n",
            " [-9.200000e+01 -6.043750e+01 -1.058750e+02 -1.165625e+02 -9.025000e+01\n",
            "  -8.675000e+01 -9.268750e+01 -1.068125e+02 -9.337500e+01 -8.512500e+01]\n",
            " [-1.091250e+02 -7.306250e+01 -8.075000e+01 -9.150000e+01 -9.356250e+01\n",
            "  -1.213750e+02 -1.115000e+02 -8.625000e+01 -9.893750e+01 -8.443750e+01]\n",
            " [-7.568750e+01 -9.418750e+01 -8.862500e+01 -1.010000e+02 -7.843750e+01\n",
            "  -1.021250e+02 -1.082500e+02 -8.087500e+01 -7.787500e+01 -5.143750e+01]\n",
            " [-1.250000e+01 -9.875000e+00  2.250000e+00 -1.350000e+01 -1.481250e+01\n",
            "  -5.043750e+01 -1.837500e+01 -1.012500e+01 -1.712500e+01 -1.300000e+01]\n",
            " [-3.750000e-01 -3.750000e-01  0.000000e+00 -6.250000e-01  2.750000e+00\n",
            "  -3.750000e-01 -1.250000e-01 -1.875000e-01 -2.500000e-01 -1.937500e+00]\n",
            " [ 0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n",
            "   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00]\n",
            " [-1.462500e+01 -3.018750e+01 -3.456250e+01 -3.487500e+01 -2.381250e+01\n",
            "  -1.450000e+01 -9.937500e+00 -2.818750e+01 -1.900000e+01 -2.181250e+01]\n",
            " [-8.581250e+01 -8.937500e+01 -1.185000e+02 -1.139375e+02 -7.962500e+01\n",
            "  -7.543750e+01 -8.537500e+01 -9.093750e+01 -9.843750e+01 -8.143750e+01]\n",
            " [-1.115625e+02 -1.053125e+02 -1.281875e+02 -1.230000e+02 -1.018750e+02\n",
            "  -1.093750e+02 -1.023125e+02 -1.223750e+02 -9.443750e+01 -8.525000e+01]\n",
            " [-1.313750e+02 -9.850000e+01 -1.218125e+02 -9.737500e+01 -1.027500e+02\n",
            "  -9.631250e+01 -1.136875e+02 -9.800000e+01 -1.082500e+02 -1.060000e+02]\n",
            " [-7.637500e+01 -6.412500e+01 -7.487500e+01 -9.275000e+01 -8.606250e+01\n",
            "  -7.925000e+01 -7.162500e+01 -7.056250e+01 -7.112500e+01 -5.825000e+01]\n",
            " [-7.500000e+00 -1.300000e+01 -7.437500e+00 -3.181250e+01  3.062500e+00\n",
            "  -3.031250e+01 -2.487500e+01  1.437500e+00 -1.268750e+01 -9.687500e+00]\n",
            " [-6.250000e-02 -6.250000e-02  0.000000e+00  0.000000e+00  4.375000e-01\n",
            "  -6.250000e-02 -6.250000e-02 -1.875000e-01 -1.250000e-01 -2.500000e-01]\n",
            " [ 0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n",
            "   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00]\n",
            " [-3.937500e+00 -1.800000e+01 -1.906250e+01 -1.437500e+01 -2.125000e+00\n",
            "  -7.437500e+00  2.625000e+00 -8.062500e+00 -2.206250e+01 -3.531250e+01]\n",
            " [-5.762500e+01 -5.056250e+01 -7.818750e+01 -7.181250e+01 -5.437500e+01\n",
            "  -5.162500e+01 -6.100000e+01 -5.662500e+01 -6.781250e+01 -6.737500e+01]\n",
            " [-1.060000e+02 -9.712500e+01 -9.875000e+01 -8.850000e+01 -9.637500e+01\n",
            "  -1.079375e+02 -8.331250e+01 -9.843750e+01 -7.381250e+01 -8.056250e+01]\n",
            " [-1.160000e+02 -9.875000e+01 -9.556250e+01 -9.281250e+01 -8.493750e+01\n",
            "  -1.110625e+02 -9.643750e+01 -8.943750e+01 -9.068750e+01 -1.025000e+02]\n",
            " [-8.300000e+01 -7.768750e+01 -9.318750e+01 -9.593750e+01 -6.775000e+01\n",
            "  -8.300000e+01 -8.743750e+01 -7.143750e+01 -1.006250e+02 -8.475000e+01]\n",
            " [-1.550000e+01 -3.012500e+01 -3.106250e+01 -5.687500e+00  2.375000e+00\n",
            "  -1.043750e+01 -4.125000e+00 -4.375000e+00 -3.925000e+01 -2.718750e+01]\n",
            " [ 0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n",
            "   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00]\n",
            " [ 0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n",
            "   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00]\n",
            " [-1.193750e+01 -2.406250e+01 -1.375000e+00 -1.400000e+01  1.843750e+01\n",
            "  -1.656250e+01 -2.206250e+01 -7.250000e+00 -1.050000e+01 -1.262500e+01]\n",
            " [-5.093750e+01 -6.825000e+01 -5.962500e+01 -7.400000e+01 -5.937500e+01\n",
            "  -8.293750e+01 -3.437500e+01 -6.287500e+01 -4.068750e+01 -8.550000e+01]\n",
            " [-6.300000e+01 -3.762500e+01 -3.687500e+01 -8.956250e+01 -3.331250e+01\n",
            "  -7.137500e+01 -5.212500e+01 -5.868750e+01 -5.750000e+01 -1.033125e+02]\n",
            " [-7.893750e+01 -7.493750e+01 -9.893750e+01 -6.443750e+01 -6.387500e+01\n",
            "  -8.262500e+01 -6.300000e+01 -7.043750e+01 -5.431250e+01 -9.906250e+01]\n",
            " [-7.887500e+01 -9.018750e+01 -9.787500e+01 -7.243750e+01 -7.950000e+01\n",
            "  -8.875000e+01 -8.475000e+01 -9.250000e+01 -7.956250e+01 -1.071250e+02]\n",
            " [-2.593750e+01 -4.875000e+01 -3.175000e+01 -5.000000e+00 -1.518750e+01\n",
            "  -2.512500e+01 -1.418750e+01 -2.375000e+01 -1.475000e+01 -4.850000e+01]\n",
            " [ 0.000000e+00 -1.875000e-01  4.375000e-01 -3.750000e-01 -5.000000e-01\n",
            "  -1.875000e-01  7.500000e-01  0.000000e+00 -1.250000e-01  0.000000e+00]\n",
            " [-1.875000e-01 -1.875000e-01  1.875000e-01  0.000000e+00 -1.875000e-01\n",
            "   0.000000e+00 -1.875000e-01  0.000000e+00 -1.875000e-01  0.000000e+00]\n",
            " [-1.368750e+01 -6.750000e+00  1.437500e+00 -8.125000e+00  2.500000e+00\n",
            "   4.437500e+00 -1.131250e+01 -9.812500e+00 -1.018750e+01 -1.750000e+00]\n",
            " [-6.712500e+01 -8.331250e+01 -7.518750e+01 -8.068750e+01 -8.643750e+01\n",
            "  -8.437500e+01 -6.281250e+01 -8.143750e+01 -6.281250e+01 -8.300000e+01]\n",
            " [-8.675000e+01 -8.031250e+01 -5.856250e+01 -1.005000e+02 -8.462500e+01\n",
            "  -1.020000e+02 -8.975000e+01 -8.543750e+01 -1.020625e+02 -1.006250e+02]\n",
            " [-8.812500e+01 -7.387500e+01 -6.975000e+01 -9.412500e+01 -8.600000e+01\n",
            "  -9.025000e+01 -9.900000e+01 -1.005625e+02 -1.148750e+02 -9.662500e+01]\n",
            " [-8.718750e+01 -9.256250e+01 -7.550000e+01 -7.918750e+01 -1.063125e+02\n",
            "  -8.350000e+01 -7.800000e+01 -1.110000e+02 -8.625000e+01 -8.956250e+01]\n",
            " [-3.175000e+01 -3.793750e+01 -1.887500e+01 -6.687500e+00 -3.756250e+01\n",
            "  -4.731250e+01 -2.062500e+01 -3.243750e+01 -1.543750e+01 -2.387500e+01]\n",
            " [-1.812500e+00  6.875000e+00  1.437500e+00 -8.750000e+00 -1.125000e+00\n",
            "  -8.750000e-01 -5.250000e+00 -3.125000e-01 -1.375000e+00  3.875000e+00]\n",
            " [-6.250000e-02 -6.250000e-02  6.250000e-02  0.000000e+00 -6.250000e-02\n",
            "   0.000000e+00 -6.250000e-02  0.000000e+00 -6.250000e-02  0.000000e+00]\n",
            " [-1.250000e+00 -1.000000e+00  5.812500e+00 -6.250000e-02 -4.437500e+00\n",
            "   3.812500e+00 -2.312500e+00  6.250000e-02 -4.375000e+00 -6.812500e+00]\n",
            " [-5.681250e+01 -6.556250e+01 -4.581250e+01 -3.843750e+01 -5.093750e+01\n",
            "  -3.131250e+01 -5.675000e+01 -5.468750e+01 -7.475000e+01 -5.131250e+01]\n",
            " [-9.775000e+01 -1.055000e+02 -1.070000e+02 -1.011250e+02 -1.157500e+02\n",
            "  -9.287500e+01 -1.184375e+02 -1.243125e+02 -1.135000e+02 -1.014375e+02]\n",
            " [-1.171250e+02 -1.095625e+02 -1.071875e+02 -1.156875e+02 -1.175000e+02\n",
            "  -1.080000e+02 -1.172500e+02 -1.189375e+02 -9.812500e+01 -1.094375e+02]\n",
            " [-6.893750e+01 -6.312500e+01 -6.312500e+01 -7.075000e+01 -8.100000e+01\n",
            "  -6.556250e+01 -6.687500e+01 -8.350000e+01 -7.900000e+01 -6.162500e+01]\n",
            " [-1.312500e+01  2.750000e+00  5.312500e+00 -9.875000e+00 -1.800000e+01\n",
            "  -2.887500e+01 -1.543750e+01 -2.306250e+01 -2.593750e+01 -1.481250e+01]\n",
            " [-2.000000e+00  1.212500e+01  5.562500e+00 -6.250000e+00 -6.250000e-02\n",
            "  -3.625000e+00 -7.937500e+00 -1.312500e+00 -5.000000e+00 -2.937500e+00]]\n"
          ]
        }
      ],
      "source": [
        "W, E, k = perceptro(X_train, y_train)\n",
        "print(\"Nombre d'iteracions executades: \", k)\n",
        "print(\"Nombre d'errors d'entrenament: \", E)\n",
        "print(\"Vectors de pesos de les classes (en columnes i amb notació homogènia):\\n\", W);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO2sOdfnvd5N"
      },
      "source": [
        "**Càlcul de la taxa d'error en test:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6fCZs5u_vd5O",
        "outputId": "e171e557-fffd-438b-9dfe-accfb807c945",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taxa d'error en test: 4.4%\n"
          ]
        }
      ],
      "source": [
        "X_testh = np.hstack([np.ones((len(X_test), 1)), X_test])\n",
        "y_test_pred  = np.argmax(X_testh @ W, axis=1).reshape(-1, 1)\n",
        "err_test = np.count_nonzero(y_test_pred != y_test) / len(X_test)\n",
        "print(f\"Taxa d'error en test: {err_test:.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax([[2,3,1],[4,7,1]])"
      ],
      "metadata": {
        "id": "7ESFH6XX7VA9",
        "outputId": "9167f093-fc41-4349-be3e-d78857ed0a22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVlayHKcvd5P"
      },
      "source": [
        "**Ajust del marge:** $\\;$ experiment per a aprendre un valor de $b$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3sCCjtG5vd5P",
        "outputId": "2ac72438-e8fd-4388-e392-63934cdd76bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b: 0.0 E: 0 k: 112 err_test: 4.2%\n",
            "b: 0.01 E: 0 k: 130 err_test: 3.6%\n",
            "b: 0.1 E: 0 k: 111 err_test: 4.4%\n",
            "b: 10 E: 0 k: 187 err_test: 5.0%\n",
            "b: 100 E: 0 k: 752 err_test: 4.4%\n"
          ]
        }
      ],
      "source": [
        "for b in (.0, .01, .1, 10, 100):\n",
        "    W, E, k = perceptro(X_train, y_train, b=b, K=1000)\n",
        "    X_testh = np.hstack([np.ones((len(X_test), 1)), X_test])\n",
        "    y_test_pred  = np.argmax(X_testh @ W, axis=1).reshape(-1, 1)\n",
        "    err_test = np.count_nonzero(y_test_pred != y_test) / len(X_test)\n",
        "    print(f\"b: {b} E: {E} k: {k} err_test: {err_test:.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MckHRV8fvd5Q"
      },
      "source": [
        "**Interpretació de resultats:** $\\;$ les dades d'entrenament no semblen linealment separables; no està clar que un marge major que zero puga millorar resultats, sobretot perquè sols tenim $30$ mostres de test; amb marge nul ja hem vist que s'obté un error (en test) del $16.7\\%$"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}