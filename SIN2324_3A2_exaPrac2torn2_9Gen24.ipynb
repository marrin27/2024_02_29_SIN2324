{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIN2324, grup de laboratori 3A2 (valencià)\n",
    "# Examen de la pràctica 2\n",
    "# Torn 2: de 8.45h a 9.30h del 9 de gener de 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressió logística aplicada a una tasca d'openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Preliminars\n",
    "\n",
    "Les següents cel·les de codi lligen una matriu de dades d'openml i creen d'un partició train-test per a fer experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Program Files\\Python\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Program Files/Python/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.filterwarnings(\"ignore\"); import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Program Files\\Python\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Program Files/Python/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "data_id = 54\n",
    "X, y = fetch_openml(data_id=data_id, return_X_y=True, as_frame=False)\n",
    "mask = ~np.isnan(X).any(axis=1); X = X[mask, :]; y = y[mask]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Experiment bàsic amb regressió logística\n",
    "\n",
    "Calcula l'error en test de regressió logística amb els valors per omissió que empra la implementació de sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escriu codi: ha d'escriure \"Error de test: <error>%\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = LogisticRegression(random_state=23).fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "err_test = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
    "print(f\"Error de test: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Comparació de solvers\n",
    "\n",
    "Sklearn empra el solver `solver=lbfgs` per omissió. Calcula l'error en test de regressió logística amb altres solvers i `max_iter=10000`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Program Files\\Python\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Program Files/Python/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Escriu codi: per cada solver provat, ha d'escriure una línia\n",
    "# \"Error de test després d'entrenar amb el solver <solver>: <error>%\"\n",
    "for solver in ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']:\n",
    "    clf = LogisticRegression(random_state=23, solver=solver, max_iter=10000).fit(X_train, y_train)\n",
    "    err_test = 1 - accuracy_score(y_test, clf.predict(X_test))\n",
    "    print(f\"Error de test després d'entrenar amb el solver {solver!s}: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta 1:** $\\;$ L'error obtés amb `lbfgs` coincideix amb el de l'experiment bàsic? Si no, com ho expliques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta 1:** $\\;$ Escriu una resposta breu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Comparació de toleràncies\n",
    "\n",
    "Sklearn empra tolerància `tol=1e-4` per omissió. Fent ús del millor solver trobat abans i de `max_iter=10000`, calcula l'error en test de regressió logística amb toleràncies inferiors i superiors al valor per omissió:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escriu codi: per cada tolerància provada, ha d'escriure una línia\n",
    "# \"Error de test amb tolerància <tolerància>: <error>%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta 2:** $\\;$ Si la tolerància és molt elevada, el model entrenat es quedarà subajustat o sobreajustat?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta 2:** $\\;$ Escriu una resposta breu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Comparació de valors per a l'hiper-paràmetre `C`\n",
    "\n",
    "Sklearn empra `C=1.0` per omissió. Fent ús dels millors solver i tolerància trobats abans, i de `max_iter=10000`, calcula l'error en test de regressió logística amb valors de `C` inferiors i superiors al valor per omissió:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escriu codi: per cada tolerància provada, ha d'escriure una línia\n",
    "# \"Error de test amb C <valor_de_C>: <error>%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta 3:** $\\;$ És possible millorar l'error en test amb un valor de `C` distint al d'omissió?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta 3:** $\\;$ Escriu una resposta breu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Comparació de valors per al màxim nombre d'iteracions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn empra `max_iter=100` per omissió. Ara bé, com hem fet abans, convé emprar un valor major que facilite la convergència de l'algorisme d'entrenament i interpretació de resultats. Fent ús dels millors solver, tolerància i C trobats abans, calcula l'error en test de regressió logística amb valors que incloguen 100 i 10000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escriu codi: per cada valor de max_iter provat, ha d'escriure una línia\n",
    "# \"Error de test amb max_iter <valor_de_max_iter>: <error>%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta 4:** $\\;$ Amb valors optimitzats de solver, tolerància i C, quantes iteracions cal com a mínim per a obtenir un error en test mínim?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta 4:** $\\;$ Escriu una resposta breu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
